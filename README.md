# Context-Aware-Local-RAG
Context-Aware LLM Responses with Local RAG A project that enables local Retrieval-Augmented Generation (RAG) by extracting, indexing, and retrieving text from PDFs to enhance LLM responses. Uses PyMuPDF for text extraction and integrates a retrieval mechanism for context-aware AI interactions.

# Overview
This project enhances LLM (Large Language Model) responses by integrating a local Retrieval-Augmented Generation (RAG) pipeline. It extracts text from PDFs, indexes the content, and retrieves relevant passages to provide context-aware AI responses.

# Features
PDF Processing: Automatically extracts text from PDFs using PyMuPDF.
Efficient Retrieval: Implements a text retrieval mechanism to fetch relevant information.
LLM Integration: Augments language models with locally stored knowledge for improved accuracy.
Optimized Performance: Uses quantization and efficient memory allocation to work within hardware constraints.
Device specifications: Nvidia GPU RTX 3060 6GB VRAM, 16GB RAM
